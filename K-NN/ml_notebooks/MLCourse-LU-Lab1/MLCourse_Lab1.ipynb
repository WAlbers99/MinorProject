{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "expected-celebrity"
   },
   "source": [
    "# MLCourse Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything in one cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Note: if this gives you errors, then scroll down to the section on environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "distinguished-riding"
   },
   "source": [
    "## Introduction\n",
    "This lab is intended to give you an overview of the toolkit and general way of working we'll use in the assignments in this course. It is not graded.\n",
    "\n",
    "What you will learn:\n",
    "* Using unit tests to validate your code\n",
    "* An overview of the key packages in the Python machine learning stack\n",
    "* Applying some ML basic models\n",
    "* Visualizing your results\n",
    "* Code style standards\n",
    "* What kind of editors to work with\n",
    "* The concept of a replicable working environment\n",
    "* How to submit your work (it's not graded, but you can test the workflow)\n",
    "\n",
    "\n",
    "Read the lab below and run the cells to see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "decent-wisdom"
   },
   "source": [
    "## Unit Tests\n",
    "During this course we will make extensive use of **unit tests** to test if your code is working correctly. A unit test is a test that tests one single piece of a program, by providing it some inputs and then checking if it provides the expected reactions. For example, consider this function as our \"unit\" to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "standard-territory"
   },
   "outputs": [],
   "source": [
    "def plus_one(number):\n",
    "    return 1 + number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yellow-digest"
   },
   "source": [
    "We can test if it behaves as it should by using `assert` statements. For example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic-fisher"
   },
   "outputs": [],
   "source": [
    "assert plus_one(1) == 2\n",
    "assert plus_one(10) == 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yellow-attraction"
   },
   "source": [
    "When we execute the code and the assertion is satisfied, it continues silently. If it doesn't return what we expected, then it raises an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grave-excitement",
    "outputId": "bd571393-816d-4948-b9da-a5ec530fb3c9"
   },
   "outputs": [],
   "source": [
    "assert plus_one('two') == 'three'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective-proposal"
   },
   "source": [
    "We can use this as a method of developing a program. It works like this:\n",
    "\n",
    "1. Decide what you want the function to do.\n",
    "2. Write the absolute minimum skeleton of the function.\n",
    "3. Write the unit tests.\n",
    "4. Try out the unit tests. **They should fail** because you haven't really built your function yet. If the tests pass before you even made the function, then your tests are clearly broken.\n",
    "5. Work on your function.\n",
    "6. Try the tests. If any of them fail, go back to 5.\n",
    "7. Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "varying-syntax"
   },
   "source": [
    "#### Exercise 1\n",
    "Take the following code skeleton and develop the `hello` function until it passes the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lonely-theater",
    "outputId": "c0249361-931f-4f9d-df08-cf69c4698843"
   },
   "outputs": [],
   "source": [
    "def hello():\n",
    "    pass\n",
    "\n",
    "assert hello('World') == 'Hello World!'\n",
    "assert hello('you') == 'Hello You!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "negative-measurement"
   },
   "source": [
    "## A tour of the tech stack\n",
    "Not every ML project uses the same packages of course, but these are particularly common:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "super-census"
   },
   "source": [
    "### Numpy\n",
    "Numpy is the workhorse for all the other packages. The most important thing that numpy does is implement **arrays**. You've probably seen arrays in C++ before, and they seemed much less flexible than Python lists right? That's true, you can put only one kind of data in an array (integers, strings, Booleans..), while lists are more flexible. \n",
    "\n",
    "But this limitation has an advantage: the size of each element is completely predictable. If you have an array that will only contain 64-bit floating point numbers, you know exactly how much memory you need for that. And you can put all those numbers next to each other in the memory. \n",
    "\n",
    "This allows you to access them much faster than the elements of a list. Because in a list every element could be a different size, and the size of an element in the middle could change if you assign something else to it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pregnant-elevation",
    "outputId": "ea1cc91b-24d9-4489-d518-e008dc864747"
   },
   "outputs": [],
   "source": [
    "my_list = [1, 2, 3]\n",
    "my_list[1] = 'foo'\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuzzy-contractor"
   },
   "source": [
    "So the length of memory you'd need to store the elements of a list is a bit harder to predict, which makes accessing them a  it slower.\n",
    "\n",
    "Another big contribution of numpy is that it has a lot of highly optimized C code hidden under the hood, that lets you do math with the easy writing of Python but the speed of C.\n",
    "\n",
    "Let's take a look at some example code. We start out by importing **numpy**, and this is commonly done as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "structural-morning"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "based-restriction"
   },
   "source": [
    "The \"as np\" renames the numpy *namespace* to np, so that we can be a bit more brief. This is nice because we might be calling a lot of numpy functions nested together in one line.\n",
    "\n",
    "Now let's see what a numpy array looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "narrative-wrapping",
    "outputId": "7ecfeeda-0815-4c87-cfa4-69ca6105b8c3"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)  # tell numpy to make numbers from 0 up to but not including 10\n",
    "print(a, '\\n')\n",
    "b = np.array([1, 2, 3])  # you can also turn a list into an array\n",
    "print(b, '\\n')\n",
    "c = np.zeros(shape=(10,5))  # arrays can be multi-dimensional\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "powered-insert"
   },
   "source": [
    "Okay, so arrays look a lot like lists or matrices, guaranteed to contain only one type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "widespread-glenn"
   },
   "source": [
    "#### Speed benefits of numpy\n",
    "Now let's take a look at these supposed speed benefits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atlantic-marble",
    "outputId": "0b129958-7b15-4d14-c1d9-c8a48c973166"
   },
   "outputs": [],
   "source": [
    "a = np.arange(100000)  # make an array filled with the numbers 0...99999\n",
    "%timeit np.sum(a)  # sum all these numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "threatened-drink"
   },
   "source": [
    "the `%timeit` is what is known as a \"magic command\". It's a function of jupyter notebook that allows us to measure how long a piece of code takes to run. We can also apply it to a whole cell with %%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nutritional-newman",
    "outputId": "6b3cd3d1-43cd-4bb1-aba1-bc5d383e711c"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.arange(100000)\n",
    "b = np.arange(100000)\n",
    "np.sum(a) + np.sum(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blank-circuit"
   },
   "source": [
    "Now let's compare that to Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "understood-mixture",
    "outputId": "82bdf54c-1931-410c-9007-890a3554faf8"
   },
   "outputs": [],
   "source": [
    "a = list(range(100000))  # make a list with the numbers 0...99999\n",
    "%timeit sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "associate-closing"
   },
   "source": [
    "Even the basic Python version doesn't take that long, because this is still a toy example. But you can see the difference, and when we start using much bigger amounts of data it adds up quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ready-martin"
   },
   "source": [
    "#### Selecting parts of a numpy array\n",
    "You can also use slices to select parts of an array, just like you can with a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "collect-chain",
    "outputId": "9a001b20-94ef-4d6e-acba-4688228e6e54"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "print(a[2:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vocal-dealing"
   },
   "source": [
    "But there's also something you can do with arrays, that you can't do with a list: select using a sequence of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "historical-credit",
    "outputId": "5b1df708-9a4e-4767-97d2-3cb3f4c83a06"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "print(a[[1, 7, 4]])  # print elements 1, 7 and 4 from the array, in that order\n",
    "\n",
    "b = list(range(10))\n",
    "# print(b[[1, 7, 4]])  # this will give an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prompt-blake"
   },
   "source": [
    "Being able to select elements in that order is nice, because it allows you to for example make a random selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "different-antibody",
    "outputId": "f9cbb272-bd6a-42b0-fe56-bd8b893c9fc5"
   },
   "outputs": [],
   "source": [
    "a = np.array(['a', 'b', 'c', 'd', 'e'])  # numpy arrays can also hold strings\n",
    "b = np.random.choice(5, size=2, replace=False)  # 2 random numbers from the range [0, 4], without replacement\n",
    "print(b)\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "incoming-marketplace"
   },
   "source": [
    "We can also select from an array using a sequence of Booleans, where only the array elements at \"True\" places get returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "experimental-assignment",
    "outputId": "cffeea5f-65d5-44c0-f728-3b2bc30e5c1f"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "b = [False, True, True, False, False, False, True, True, False, False]\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rising-mississippi"
   },
   "source": [
    "#### Element-wise operations\n",
    "Another of the defining features of numpy is the ability to do **element-wise** operations on a whole array at once. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "announced-cedar",
    "outputId": "589800ea-559b-453e-f2ba-4c9ab7231dd7"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "even = a % 2 == 0  # 'True' for each number in a that is fully divisible by 2\n",
    "print(even)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "simple-watson"
   },
   "source": [
    "#### Conditional Selection\n",
    "We can put this together with the Boolean selection we showed above, and use it to select part of an array based on some test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "german-chinese",
    "outputId": "4473bf40-3852-4ca3-f9e2-17cc30646bb5"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "even_indices = a % 2 == 0\n",
    "print(even_indices)\n",
    "\n",
    "even_numbers = a[even_indices]  # select items from a that are True\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "formal-treasurer"
   },
   "source": [
    "In practice, we tend to write this a bit more concisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "horizontal-focus",
    "outputId": "f950b2a9-23a1-4aed-c9af-81f248fd694f"
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "even_numbers = a[a % 2 == 0]\n",
    "print(even_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amazing-survival"
   },
   "source": [
    "#### Views vs. Copies\n",
    "Depending on how you select from an array, you may get a **view** or a **copy**.\n",
    "* If you modify a view of an array, you also change the original. The view is just a different way of looking at the original object.\n",
    "* If you modify a copy of an array, the original isn't changed. The copy is a new object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "british-munich",
    "outputId": "beab55ff-9308-4591-f180-c61831e8e69a"
   },
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2, 3, 4, 5])\n",
    "print('a', a)\n",
    "b = a[1:3]  # we get a view\n",
    "print('b', b)\n",
    "b[0] = 10\n",
    "print('b', b)\n",
    "print('a', a)  # look, 'a' has been changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maritime-point",
    "outputId": "27033fdf-2850-4e0a-ec34-046d8d31a0d3"
   },
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2, 3, 4, 5])\n",
    "print('a', a)\n",
    "b = a[[1, 2]]  # we get a copy because we used \"fancy indexing\"\n",
    "print('b', b)\n",
    "b[0] = 10\n",
    "print('b', b)\n",
    "print('a', a)  # look, 'a' was NOT changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "organizational-links",
    "outputId": "5380aec3-9508-435a-9a23-d961ba0ce6ac"
   },
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2, 3, 4, 5])\n",
    "print('a', a)\n",
    "b = a[1:3].copy()  # we explicitly ask for a copy\n",
    "print('b', b)\n",
    "b[0] = 10\n",
    "print('b', b)\n",
    "print('a', a)  # look, 'a' was NOT changed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nearby-oasis"
   },
   "source": [
    "The middle example used what is called \"fancy indexing\". The bottom example used an explicit copy statement. The Zen of Python says that *Explicit is better than implicit*, and it's true, it's much more easy to see that the third example will make a copy than the second one. It's also an example of *in the face of ambiguity, refuse the temptation to guess*.\n",
    "\n",
    "There is a way of testing whether one array is a view of another one. You can ask if one array `is` the `base` of another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fundamental-devon",
    "outputId": "8715da71-8ab5-4859-d340-556ba1c696da"
   },
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2, 3, 4, 5])\n",
    "b = a[1:3]\n",
    "b.base is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gorgeous-sheffield",
    "outputId": "01f56dab-5843-4b4f-888f-d6a3c6fb8048"
   },
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2, 3, 4, 5])\n",
    "b = a[[1, 2]]\n",
    "b.base is a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geological-causing"
   },
   "source": [
    "Obviously, mixing up whether you're using a view when you should be using a copy is going to cause some strange bugs in your code. So what are advantages of views?\n",
    "* You don't have to copy all that data to a new place in memory. This saves time when handling large arrays.\n",
    "* You don't need memory to hold *both* arrays. Again, with large arrays this is helpful.\n",
    "\n",
    "So depending on what exactly you want to do, either one would be the right answer. If you know you're not going to modify the selected data, then it's safe to use a view. This happens quite often actually, if it's just an input value for another calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "physical-creek"
   },
   "source": [
    "#### Assignment to parts of the array at once\n",
    "Since we're able to select whole parts of an array, we can also use that to assign to all of it at once. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dense-waters",
    "outputId": "ca04600d-df8d-46e4-fe62-2deb03c491e7"
   },
   "outputs": [],
   "source": [
    "a = np.zeros(10)\n",
    "print(a)\n",
    "a[2:5] = 5  # assign one element to the whole selection\n",
    "print(a)\n",
    "a[5:7] = [6, 7]  # assign a sequence of the same length as the selected target\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "automotive-traveler"
   },
   "source": [
    "#### Exercise 2: rolling an array\n",
    "Implement code inside the `roll_array` function so that it passes the unit tests. The idea of \"rolling\" an array is moving all the values in it either to the right, or left. Values that would fall out on one end are put in on the other end. For example, if we rolled (1, 2, 3, 4) one space to the right we'd get (4, 1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final-bathroom",
    "outputId": "5634f390-0c67-49c7-a381-cb81cd0370a6"
   },
   "outputs": [],
   "source": [
    "def roll_array(array, steps, direction='left'):\n",
    "    '''Roll the contents of a 1D array, \"steps\" steps in the given direction, wrapping around. '''\n",
    "    raise NotImplementedError('Your code here')\n",
    "    return rolled_array\n",
    "\n",
    "a = np.arange(10)\n",
    "print(a)\n",
    "\n",
    "assert np.array_equal(\n",
    "    roll_array(a, 2, 'right'),\n",
    "    np.asarray([8, 9, 0, 1, 2, 3, 4, 5, 6, 7])\n",
    ")\n",
    "\n",
    "assert np.array_equal(\n",
    "    roll_array(a, 4, 'left'),\n",
    "    np.asarray([4, 5, 6, 7, 8, 9, 0, 1, 2, 3])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "functional-structure"
   },
   "source": [
    "### Pandas\n",
    "The next commonly used package is pandas. Pandas is built on top of numpy; on the inside of a pandas DataFrame the data is stored in numpy arrays. Let's look at some example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lasting-immigration"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "focal-trust"
   },
   "outputs": [],
   "source": [
    "some_data = np.reshape(np.arange(20), (-1, 4))  # make a 2d numpy array\n",
    "print(some_data, '\\n\\n')\n",
    "\n",
    "df = pd.DataFrame(data=some_data, columns=['col1', 'col2', 'col3', 'col4'])  # make a pandas DataFrame\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anonymous-forestry"
   },
   "source": [
    "You can think of numpy as being like a vector or matrix in a mathematical sense. Pandas is more like a spreadsheet, although it also has some tricks that may remind you more of a database system like SQL.\n",
    "\n",
    "We called out dataframe `df`. This is quite common practice because it's nice and short. You often end up using the same dataframe multiple times in a single line, so a long variable name isn't helpful then. However, if you're using multiple dataframes, make sure to give them informative names.\n",
    "\n",
    "It's got two main data types: the DataFrame (a table) and the Series (one column or row). But underneath it's numpy, and you can extract numpy arrays from it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "identical-geneva"
   },
   "outputs": [],
   "source": [
    "a = df['col1'].values\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "signal-offer"
   },
   "source": [
    "So what's the point of Pandas? Convenience, mostly. Numpy stands for \"numeric python\" and it's rather low-level. Pandas is an abstraction layer on top of it that gives you more convenient  and human-understandable ways to handle data. For example:\n",
    "* Having names on columns\n",
    "* Being able to index rows by date\n",
    "* Quick statistical summaries of the contents of your table\n",
    "* Ability to merge two pandas dataframes much like you might join tables in SQL.\n",
    "* Ability to output a table into fully formatted LaTeX code. (This is an amazing work-saver.)\n",
    "* Easy import and export of CSV and other spreadsheet files.\n",
    "* Some built-in plotting functionality.\n",
    "* Ability to aggregate rows in ways similar to SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reliable-shopper"
   },
   "source": [
    "Mastering all the tricks in pandas will take some time. Here we'll just cover a couple of key functions needed to get you started. Let's start with some handy preview functions for viewing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "negative-cliff"
   },
   "outputs": [],
   "source": [
    "df.head(3)  # show only the first 3 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vulnerable-composite"
   },
   "source": [
    "The `head` function shows a couple of rows in the dataset, which can be handy when you need a quick look at what's in there but printing thousands of rows isn't really useful. There is also a `tail` function that works the same, but at the bottom of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "instrumental-primary"
   },
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toxic-destruction"
   },
   "source": [
    "The `info` function gives you an overview of what's in your columns. The non-null column shows you whether there are missing values in your data, and the Dtype column shows what kind of data there are. Since we built this dataframe from integers, that's what it says there. Other datatypes are for example floats, datetime and object. Remember that since pandas uses numpy under the hood, everything in one column has to be the same datatype. If there are in fact things with different datatypes in a column, then pandas uses the super-broad datatype \"object\" that can fit any of the other datatypes. So if you see \"object\" as a datatype in this function, you might have to do some more data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "corporate-listening"
   },
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "contemporary-trauma"
   },
   "source": [
    "The `describe` function gives a quick statistical overview of your columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alone-breast"
   },
   "source": [
    "The other topic is how to **select** in pandas. This can be a bit confusing, because there are multiple ways to do it. The main ways are:\n",
    "- with brackets\n",
    "- with the dot\n",
    "- with `loc`\n",
    "- with `iloc`\n",
    "\n",
    "Each of these has its own uses, although with `loc` and `iloc` you can do everything that the others could - those are more like a shorthand. We'll give a brief explanation of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "modern-humanity"
   },
   "source": [
    "#### Using `.iloc`\n",
    "iloc stands for integer location. You indicate the part of the dataframe you want to select using its integer index. This is quite similar to accessing an element in numpy or even a nested list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hispanic-ambassador"
   },
   "outputs": [],
   "source": [
    "df.iloc[0:3]  # select rows 0 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "internal-probe"
   },
   "outputs": [],
   "source": [
    "df.iloc[[0, 3]]  # select row 0 and 3. Notice the inner list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "funded-craft"
   },
   "outputs": [],
   "source": [
    "df.iloc[:, 0:3]  # select columns 0 to 3. Notice the : to the left that selects all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "recent-radical"
   },
   "outputs": [],
   "source": [
    "df.iloc[:, [0, 3]] # select columns 0 and 3. Notice both the inner list and : to the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "novel-champion"
   },
   "outputs": [],
   "source": [
    "df.iloc[1, 2] # select cell (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "equal-measurement"
   },
   "outputs": [],
   "source": [
    "df.iloc[2:4, 0:2]  # select the cells on rows 2 to 4, columns 0 to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alike-cruise"
   },
   "source": [
    "You may have noticed that `iloc` doesn't care that we called our columns \"col1\"; as far as iloc is concerned, counting starts at 0 and the names of the columns are not important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "realistic-emerald"
   },
   "source": [
    "#### Dots\n",
    "With dots we can quickly select a single column by name. This can be convenient because it's very compact writing, but apart from that it's a bit limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuzzy-electricity"
   },
   "outputs": [],
   "source": [
    "df.col3  # select col3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intellectual-honey"
   },
   "source": [
    "#### Brackets\n",
    "With brackets we can also select columns by name. However, we can do a bit more with it than with the dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vital-investor"
   },
   "outputs": [],
   "source": [
    "df['col1']  # select the column named 'col1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "earned-music"
   },
   "outputs": [],
   "source": [
    "df[['col1', 'col3']]  # select col1 and col3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mobile-blood"
   },
   "outputs": [],
   "source": [
    "df[['col3', 'col1']]  # we can select the columns in a different order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "correct-conservative"
   },
   "source": [
    "#### Using `.loc`\n",
    "`loc` is one of the most powerful ways of accessing a pandas dataframe. While `iloc` selected by integer-index, `loc` selects by **label**.\n",
    "\n",
    "The notation for using loc uses either `.loc[row labels]` as style when we're only selecting some rows,  `.loc[:, column labels]` when we only want to select columns, or `.loc[rows, columns]` when we want to select both.\n",
    "\n",
    "One pitfall when using `.loc` to access a slice, like `.loc['col1':'col3']`, is that the selection *includes* the last element, so you'd get three columns this way. This makes it different from most other slice notation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optical-corporation"
   },
   "outputs": [],
   "source": [
    "df.loc[0]  # show the row named '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "listed-printer"
   },
   "outputs": [],
   "source": [
    "df.loc[0:2]  # show all the rows starting at the row labeled '0', up to and INCLUDING '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "polish-football"
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'col1']  # show col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuzzy-sending"
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'col1':'col3']  # show columns starting at the one labeled 'col1' up to and INCLUDING 'col3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "helpful-danish"
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['col1', 'col3']]  # show 'col1' and 'col3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "controlling-immune"
   },
   "outputs": [],
   "source": [
    "df.loc[:, ['col3', 'col1']]  # we can also change the order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "confirmed-boards"
   },
   "source": [
    "You'll notice that using `.loc` to access rows didn't look that different from using `.iloc`. This is because we didn't explicitly define the indices of our rows, so they were initialized by pandas starting at 0. But we can explicitly name the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scenic-sociology"
   },
   "outputs": [],
   "source": [
    "num_rows = df.shape[0]  # shape tells you the  (numer of rows, number of columns) of the DataFrame\n",
    "print(num_rows)\n",
    "\n",
    "new_nums = reversed(range(num_rows))  # get the numbers 0-4, but reversed\n",
    "\n",
    "names = [f'row{i}' for i in new_nums]  # use a \"list comprehension\" to build a list of names\n",
    "print(names)\n",
    "\n",
    "df.index = names  # change the index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "handmade-desire"
   },
   "source": [
    "Now let's look at what `.loc` and `.iloc` do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tamil-request"
   },
   "outputs": [],
   "source": [
    "df.loc['row0':'row2']  # nothing, because row2 comes before row0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noticed-meter"
   },
   "outputs": [],
   "source": [
    "df.loc['row0':'row2':-1]  # walk in reverse order, now we get rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "funded-civilian"
   },
   "outputs": [],
   "source": [
    "df.iloc[0:2]  # we just get the first two rows in the table, regardless of the labels in the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "american-boundary"
   },
   "source": [
    "#### Conditional selection with `.loc`\n",
    "One of the most powerful things we can do with `.loc` is conditional selection. Basically, we use some conditions which when evaluated against the dataframe, give a True or False on whether that part of the frame should be included. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "federal-poverty"
   },
   "outputs": [],
   "source": [
    "div3 = df.col3 % 3 == 0  # True if the element in col3 is divisible by 3\n",
    "\n",
    "df.loc[div3]  # Perform the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quick-division"
   },
   "outputs": [],
   "source": [
    "df.loc[df['col1'] > 10]  # select rows where col1 > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interim-subcommittee"
   },
   "outputs": [],
   "source": [
    "df.loc[df['col1'] % 3 == 0, ['col2', 'col3']]  # select col2 and col3 only if col1 is divisible by 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "concrete-gather"
   },
   "source": [
    "In conclusion, the four different ways of accessing pandas data are:\n",
    "* dot notation, which can only select a single column but is really short and easy to read.\n",
    "* bracket notation which gives some more freedom in selecting columns\n",
    "* `.loc` notation which allows you to select based on both row and column labels and use conditionals\n",
    "* `.iloc` notation which allows you to select based on integer-indexed location regardless of labels\n",
    "\n",
    "Each is useful in some circumstances but it can take some practice to become comfortable with all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "direct-registration"
   },
   "source": [
    "#### Assigning to selections\n",
    "There are a couple of ways you can assign data into parts of a pandas dataframe. The obvious one is to select a part of the existing dataframe and just assign to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reduced-trustee",
    "outputId": "5c58d178-e42a-4e76-8a00-e6fca6678e7f"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'a': np.arange(10), 'b':np.arange(20, 30)})\n",
    "print(temp, '\\n')\n",
    "temp.iloc[2:4,1] = 50  # select rows 2 to 4, column 1, and assign 50 to it\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aboriginal-poison"
   },
   "source": [
    "There is one other way that is used very commonly, and that is adding a whole column to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olive-serbia",
    "outputId": "90e16ea5-71c4-41ad-d6ed-8dafe6a1e685"
   },
   "outputs": [],
   "source": [
    "temp['c'] = np.arange(50, 60)  # create a new column and assign some data to it\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suspended-stanford"
   },
   "source": [
    "It's possible to append rows to a dataframe as well, but this isn't as commonly done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piano-presence"
   },
   "source": [
    "#### Exercise 3\n",
    "You have a dataframe with some height and width information and a class label, and you want to select only the class labels of items with a surface of at least `min_surface`. Complete the function body so that it passes the unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otherwise-upgrade",
    "outputId": "028afd02-b90d-4418-bfff-dba4b5e88242"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'height':[1, 2, 3, 4, 5], \n",
    "    'width':[5, 4, 8, 10, 1], \n",
    "    'class_labels': ['a', 'b', 'c', 'a', 'a']\n",
    "})\n",
    "print(df)\n",
    "\n",
    "\n",
    "def surface_class(frame, min_surface):\n",
    "    ''' Return the class labels of all rows with a surface >= least min_surface '''\n",
    "#     surface = df['height'] * df['width']\n",
    "#     enough = surface >= min_surface\n",
    "#     labels = frame.loc[enough, 'class_labels']\n",
    "    raise NotImplementedError('Your code here')\n",
    "    return labels\n",
    "\n",
    "\n",
    "\n",
    "labels = np.asarray(surface_class(df, 8))\n",
    "target = np.asarray(['b', 'c', 'a'])\n",
    "assert np.array_equal(labels, target), f\"{labels} != {target}\"\n",
    "\n",
    "labels = np.asarray(surface_class(df, 9))\n",
    "target = np.asarray(['c', 'a'])\n",
    "assert np.array_equal(labels, target), f\"{labels} != {target}\"\n",
    "\n",
    "labels = np.asarray(surface_class(df, 24))\n",
    "target = np.asarray(['c', 'a'])\n",
    "assert np.array_equal(labels, target), f\"{labels} != {target}\"\n",
    "\n",
    "labels = np.asarray(surface_class(df, 25))\n",
    "target = np.asarray(['a'])\n",
    "assert np.array_equal(labels, target), f\"{labels} != {target}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coupled-tenant"
   },
   "source": [
    "### Matplotlib\n",
    "We use matplotlib to make plots. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "significant-actor",
    "outputId": "f2acf008-814f-4756-b1c6-137b1e9f1254"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(10)\n",
    "y = x * x\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "speaking-restriction"
   },
   "source": [
    "Notice that we import the `pyplot` subpackage. This is a legacy thing, matplotlib was originally more heavily based on MATLAB. The pyplot subpackage is the more modern element that we mostly use.\n",
    "\n",
    "The basics of plotting is pretty simple; you use the `plot` or `scatter` and pass two sequences, that determine the X and Y coordinates of the points to be plotted. The `plot` command interpolates a line between them while `scatter` makes a scatterplot.\n",
    "\n",
    "We can also add many different types of styling to a plot. Some of the most common ones are:\n",
    "* color\n",
    "* marker (like the stars below)\n",
    "* linestyle\n",
    "* label (in the legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "legislative-encoding"
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(100)  # make 100 normally distributed random points\n",
    "y = np.random.randn(100)\n",
    "plt.scatter(x, y, color='red', label='a', marker='*')\n",
    "plt.legend() # indicate that we want a legend in the plot\n",
    "plt.grid() # add a grid to the plot\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "correct-expert"
   },
   "source": [
    "A good plot always has a couple of things:\n",
    "* Label on the X axis\n",
    "* Label on the Y axis\n",
    "* If either axis is expressed in some kind of unit, like centimeters, grams, seconds - then you should note that.\n",
    "* A title\n",
    "* A caption (although you typically add this in the report, not when generating it)\n",
    "* A legend, especially if you're plotting more than one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "musical-fireplace"
   },
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "y1 = (x * 1.5) + 30\n",
    "y2 = (x * 2) + 10\n",
    "plt.plot(x, y1, label='blue car', color='blue')\n",
    "plt.plot(x, y2, label='red car', color='red')\n",
    "plt.title('Red ones go faster!')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('distance (km)')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prostate-fishing"
   },
   "source": [
    "### Scikit-Learn\n",
    "Scikit-Learn, also known as `sklearn` is a package with many tools for machine learning, such as functions to prepare data for machine learning, error measures, example datasets, and many machine learning algorithms. During this course we will use this package extensively. It's the heart of the modern Python machine learning world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faced-africa"
   },
   "source": [
    "### SciPy\n",
    "SciPy is the Scientific Python package. It contains a lot of optimized functions for for example signal processing. Where SciKit-Learn focuses more on machine learning, SciPy is more of a general physics/engineering sort of package that we occasionally use a function from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "confused-distinction"
   },
   "source": [
    "### ... and many others\n",
    "There are many more packages that will receive some attention later during this course, for example:\n",
    "\n",
    "- **TensorFlow**, another workhorse package like numpy. It's named after \"tensors\", which are a generalization of the idea of vectors and matrices to any number of dimensions. One of its key features is allowing the use of GPUs and even TPUs for machine learning.\n",
    "- **Keras** is usually run on top of TensorFlow and is a package for the easy construction of neural networks. If TensorFlow is like Numpy, then Keras is like Scikit-Learn.\n",
    "- **PyTorch** provides similar functionality to TensorFlow/Keras.\n",
    "- **Auto-Sklearn** is a sort of wrapper around Scikit-Learn that can automate many of the tasks of selecting the best algorithm and configuration to use for any given machine learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "martial-empty"
   },
   "source": [
    "## Synthetic data: signal and noise\n",
    "One way of viewing a machine learning problem is to assume that the observations that we have in our dataset are a combination of *signal* and *noise*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wicked-attribute"
   },
   "source": [
    "### The convenience of a load_data function\n",
    "It can happen pretty often that you're altering your data a bit while doing experiments. Especially in Jupyter Notebook you often use some cells out of order (gasp!) and then your data can get a bit messy. An easy way to to work around this is to just write a simple function around loading/preparing/generating your data that you can call to get a fresh copy. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tutorial-johnston",
    "outputId": "e300d5ca-8800-4c66-b92b-9e782e9c0f55"
   },
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    amount=100, proportion=0.7, # By default we want 70% class a, 30% class b\n",
    "    signal_a_height=5, signal_a_width=10, a_noise=2,\n",
    "    signal_b_height=4, signal_b_width=6, b_noise=3,\n",
    "    random_state=42  # by default, always generate the same data\n",
    "):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Calculate how many instances of each class to generate\n",
    "    a_amount = int(amount * proportion)\n",
    "    b_amount = amount - a_amount\n",
    "    \n",
    "    # Generate instances of class a\n",
    "    # The height and width are the sum of signal + noise\n",
    "    a_height = signal_a_height + (np.random.randn(a_amount) * a_noise)\n",
    "    a_width = signal_a_width + (np.random.randn(a_amount) * a_noise)\n",
    "    a_labels = np.full(a_amount, 'a')\n",
    "    \n",
    "    # Do the same for b\n",
    "    b_height = signal_b_height + (np.random.randn(b_amount) * b_noise)\n",
    "    b_width = signal_b_width + (np.random.randn(b_amount) * b_noise)\n",
    "    b_labels = np.full(b_amount, 'b')\n",
    "\n",
    "    # Wrap it up in a nice dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'height': np.concatenate([a_height, b_height]),\n",
    "        'width': np.concatenate([a_width, b_width]),\n",
    "        'label': np.concatenate([a_labels, b_labels])\n",
    "    })\n",
    "    return df\n",
    "\n",
    "print(generate_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "royal-reliance"
   },
   "source": [
    "Let's see what this looks like if we plot it with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "embedded-texas",
    "outputId": "78f76752-96ee-4644-bee1-3a8c6221f373"
   },
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for label, mark in zip(['a', 'b'], ['+', 'o']):\n",
    "    instances = df.loc[df['label'] == label]\n",
    "    plt.scatter(instances['width'], instances['height'], marker=mark, color='black', label=label)\n",
    "plt.legend()\n",
    "plt.xlabel('width')\n",
    "plt.ylabel('height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urban-commonwealth"
   },
   "source": [
    "## The basics of classifiers\n",
    "When you start working with Scikit-Learn, you'll notice that although the many machine learning algorithms are quite different in theory, in practice, you can use them in much the same way. They all have some functions in common, so those were also given the same names. Scikit-Learn applies object-oriented design principles to Machine Learning; you don't have to know all that much about what's inside an object to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enhanced-amino"
   },
   "source": [
    "### A majority classifier\n",
    "Let's consider a really simple classifier. This classifier just determines what the most common label was in the training set, and predicts every new instance to be the same as that. It *should* be right more than 50% of the time, if the test data is similar to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optimum-willow"
   },
   "outputs": [],
   "source": [
    "class MajorityClassifier:\n",
    "    \"\"\" Majority classifier: classifies everything with the majority label from the training set. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.majority_label = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\" Determine which is the majority label in the training set. \"\"\"\n",
    "        unique_labels, label_frequencies = np.unique(y_train, return_counts=True)\n",
    "        majority_index = np.argmax(label_frequencies)\n",
    "        self.majority_label = unique_labels[majority_index]\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\" Predict the trained majority label in all cases. \"\"\"\n",
    "        prediction = np.full(x_test.shape[0], self.majority_label)\n",
    "        if isinstance(x_test, pd.DataFrame):\n",
    "            return pd.Series(prediction)\n",
    "        return prediction  # as a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stone-probability"
   },
   "source": [
    "Let's analyze what's happening here.\n",
    "\n",
    "- In `__init__` we make a call to `super().__init()__()` which means we look at the parent of this class and also execute that init function. After that, we create a variable `self.majority_label`.\n",
    "- In `fit` we use some convenient `numpy` functions to determine the most frequent label and memorize it in `self.majority_label`.\n",
    "- In `predict` we use `np.full` to make an entire array filled with the same value: the label of the majority class that we stored in the `fit` method.\n",
    "\n",
    "Let's see this classifier in action on our synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "invisible-harrison"
   },
   "outputs": [],
   "source": [
    "# Make some training data\n",
    "train = generate_data()\n",
    "x_train = train[['height', 'width']]\n",
    "y_train = train['label']\n",
    "\n",
    "# Make some new data to test with\n",
    "test = generate_data(random_state=43)  # we want different test data\n",
    "x_test = test[['height', 'width']]\n",
    "y_test = test['label']\n",
    "\n",
    "\n",
    "classifier = MajorityClassifier() # Initialize\n",
    "classifier.fit(x_train, y_train)  # Larn from the training data\n",
    "\n",
    "prediction = classifier.predict(x_test)  # Make a prediction about the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "disabled-cologne"
   },
   "source": [
    "Okay, now we have a prediction, what do we do with it? We can visualize it! In fact, let's write a visualization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "selective-obligation"
   },
   "outputs": [],
   "source": [
    "def visualize(x_test, y_test, prediction):\n",
    "    # Now let's inspect the result\n",
    "    plt.figure(figsize=(10,10))\n",
    "    color_map = {'b': 'red', 'a': 'blue'}\n",
    "    marker_map = {'a': '+', 'b': 'o'}\n",
    "\n",
    "    # place the scatter points one by one\n",
    "    for i in range(len(prediction)):\n",
    "        y_coord = x_test.iloc[i, 0]  # height\n",
    "        x_coord = x_test.iloc[i, 1]  # width\n",
    "        true_label = y_test.iloc[i]\n",
    "        predicted_label = prediction.iloc[i]\n",
    "        plt.scatter(\n",
    "            x_coord, y_coord, \n",
    "            color=color_map[predicted_label], marker=marker_map[true_label],\n",
    "            label=f'predicted {predicted_label} / true {true_label}'\n",
    "        )\n",
    "\n",
    "    # this is a trick to make sure we don't get duplicate handles in the legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    \n",
    "    \n",
    "    plt.xlabel('width')\n",
    "    plt.ylabel('height')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "short-budget",
    "outputId": "d4b57a1e-078a-4d35-b0af-326d5387ec13"
   },
   "outputs": [],
   "source": [
    "visualize(x_test, y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrong-memorial"
   },
   "source": [
    "Is this a good result? Well.... it's correct most of the time on the test set, since label `a` is also the majority label in the test set. If our test set had more of label `b` this classifier would do really poorly though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saving-drain"
   },
   "source": [
    "### Final Exercise: A nearest-neighbor classifier\n",
    "In this exercise you're going to make a somewhat better classifier. The \"nearest neighbor classifier\" (1NN) finds, for each instance in the test set, the nearest instance in the training set, and outputs the label of that training instance as its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "north-translator"
   },
   "outputs": [],
   "source": [
    "class OneNearestNeighborClassifier:\n",
    "    def __init__(self):\n",
    "        self.y_train = None\n",
    "        self.x_train = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\" To fit, we just store the entire training data. \"\"\"\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def distance(self, a, b):\n",
    "        \"\"\" Return the Euclidean distance between point a and b \"\"\"\n",
    "        return np.sqrt(np.sum((a - b)**2))\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\" Predict the label of test instances \n",
    "        \n",
    "        For each test instance, find the nearest point in the training set.\n",
    "        Then return a list of the labels of the nearest points that you found.\n",
    "        \"\"\"\n",
    "        prediction = []\n",
    "        raise NotImplementedError('Your code here')\n",
    "\n",
    "\n",
    "        \n",
    "        if isinstance(x_test, pd.DataFrame):\n",
    "            return pd.Series(prediction)\n",
    "        return np.asarray(prediction)  # as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saving-merchandise",
    "outputId": "3671100c-53a9-475c-9f49-82ccccff5fc4"
   },
   "outputs": [],
   "source": [
    "# Make some training data\n",
    "train = generate_data()\n",
    "x_train = train[['height', 'width']]\n",
    "y_train = train['label']\n",
    "\n",
    "# Make some new data to test with\n",
    "test = generate_data(random_state=43)  # we want different test data\n",
    "x_test = test[['height', 'width']]\n",
    "y_test = test['label']\n",
    "\n",
    "\n",
    "clf = OneNearestNeighborClassifier() # Initialize\n",
    "clf.fit(x_train, y_train)  # Larn from the training data\n",
    "\n",
    "prediction = clf.predict(x_test)  # Make a prediction about the test data\n",
    "\n",
    "visualize(x_test, y_test, prediction)  # visualize it using our function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "searching-apache"
   },
   "source": [
    "Now take a look at how the 1NN classifier performs when the test data does *not* have the same class distribution as the training data. Consider how well it can cope, and how well would the majority classifier cope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "established-lying",
    "outputId": "55999b92-92bd-4e1c-9878-f6d8f1d7ca3a"
   },
   "outputs": [],
   "source": [
    "# Make some training data\n",
    "train = generate_data()\n",
    "x_train = train[['height', 'width']]\n",
    "y_train = train['label']\n",
    "\n",
    "# Make some new data to test with\n",
    "test = generate_data(random_state=43, proportion=0.3)  # switch to class b as the most common\n",
    "x_test = test[['height', 'width']]\n",
    "y_test = test['label']\n",
    "\n",
    "\n",
    "clf = OneNearestNeighborClassifier() # Initialize\n",
    "clf.fit(x_train, y_train)  # Larn from the training data\n",
    "\n",
    "prediction = clf.predict(x_test)  # Make a prediction about the test data\n",
    "\n",
    "visualize(x_test, y_test, prediction)  # visualize it using our function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code style\n",
    "Unlike for example C++ where people just can't agree exactly what the best way is to place brackets, for Python there is just one key standard for how good clean code looks like: PEP8. PEP stands for Python Enhancement Proposal. You can find the official description [here](https://www.python.org/dev/peps/pep-0008/). A bit lighter reading version that gives more explanation is [here](https://realpython.com/python-pep8/).\n",
    "\n",
    "Writing clean code is important. It's very common that you find yourself doing some project and thinking, \"hey, I solved this little problem in another problem two months ago, how did I do that again?\" If you wrote nice clean code, it's easy to look up how you did it. Likewise, if you're working together with people, it's easier if you understand what others are doing. Adhering (sensibly) to PEP8 makes this easy.\n",
    "\n",
    "The original PEP8 standard assumes a 80-character line limit, but with modern screens, it's reasonable to assume a 120 character line limit.\n",
    "\n",
    "Python also has a very definite philosophy behind it, and knowing that philosophy will make it easier to understand how a lot of things are designed in Python. It's called The Zen of Python, officially documented as PEP20, and can be found [here](https://www.python.org/dev/peps/pep-0020/) and there are many essays explaining these 19 statements, for example [here](https://inventwithpython.com/blog/2018/08/17/the-zen-of-python-explained/). Note though that every article explaining them is subtly different. They're intended to make you think, not blindly follow :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adequate-result"
   },
   "source": [
    "## Picking a good code editor\n",
    "A good editor will make your life much easier. You could do most of your Python editing in Notepad, Gedit, or another \"dumb\" editor. The editor is pretty easy to use, you don't have to learn a new program. Sound convenient? Sure, but you're missing out on some tools to find bugs. For example, what's wrong with this code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sudden-energy"
   },
   "source": [
    "![no highlight.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rapid-victoria"
   },
   "source": [
    "Now let's suppose that you have minimal syntax highlighting, like you have in Jupyter Notebook/Google Colab or even Gedit when your syntax highlighting is set up correctly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parental-product"
   },
   "source": [
    "![highlight.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPUAAAAnCAYAAADXRw5BAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AABLTSURBVHic7Z1peBRV1oDf6u50OvtKFpYkQEICAiGIYXcAZRGQRWEcZBSFCYMjIqiAIktANuXDjRkUUBhlEUcgIuggKLKJCQiBQCBhS4AA2UgISTpLL/f7UR3shCzdIQHC9Ps8/aSr69Q9t27Vuefcc6tuJCGEwIYNGw8MintdARs2bNQt98CojZScOcDFb77kQvyNu6+eUg4l7GNi/DV090B7nWDMI2HjSr67UHqva1IDxSRvWcE3iTexhYN3D9XdV1nMtX9O4uDPRryn9qZ5hDuSNYeLPK5v/IDjG/eRk5aLQeWMpnEYgVPepcOjnhYcX0xs4lE+d/JlSYQ/drU8C6E9wROf7uRHg7ytCR1MzpBQHKyUsV5xDrEfv8asHwQDmg7H2KJR+Z65OJ3E+BRUrbsQ6m5Vy1pPTbqMOaQe+4lPVhwic8FS/tHJymtto1bUylOXpO1i0V/78udlCejrukbVIijZOZ89C78hPaUQdcv2eAX7ocy/ik7hdFdrIjmEsGLMGE68MJKZ/pU3oyUy1mHgcsw7vLNNT7/oD5jSo9FtF9CQEsOCt5ex+5qxDvTVUJuadCka03/WB0x9JJdNcxfy/dX6r5MNKz21Ie8sezZ9yRffHOBSsZFGneurWlXWgLwj8ZQaFWiGvsvAhb3uRaghI2kI9NKAKGCfXRX+xxIZKzBm72T55yfwHbWMSd08G0ZCxK4pA96aSfL4N1i54he6Rz+Gh81d1ytW2ISBlJilrDgSwPDZs8le/g77LDxSf2YzRxes5NKJLIRbE+z1em4LEnRXuPr5h5zcsp/cTB1K31b4DZ1ARNSfcLITlG59mS0z9lLW1xdvfZn/bJW/S/6jeWzHDHysOJvSS/sJX/4jl4olvDwDGPtoH+a0cPmjQUQRB+MPEH0ilcM5WhTOvgzu2JOlDzfB23I1lmHMZ+ehfcw6nkKCFvx8WhDVvSfTgszqg5HU7zcRp+rFvL+EYV+xDP0xPvzLq2zOkFtow/hebABAgfvgJWyZHikPNYx5nIxZyertcZy+fAOFVyu6Pf0SE0e2w00CY9Zu5v19Pqcj3+HT6d3xkEDkHmDR+GhOPbqEFRMjcDJYqMuE5BTBi2N78NPCTey40ptRTRtEd9RgscIMlASP+YSvX5CQDEmsXG7hYQUHiZ84l3NXjKj8QnFzzSXvnJFyRi2ukzbnRfZ/dxWlTxheEWqKTp/k0vLJ5JWsYcCUDij829O0jwJt8kGyr5SiahaBX4g7AJJnK+yt7P2VLoFM7x5Cc2UxB+P3M2/bDvxfGME/3CRAR9yvm+l/TMkLPR8n2ldN5qWjTN33LWPUz7GtnWsdeslS9uzdzNAEBc/06M98L8GJxN+YvWUTWSNH80EztSxmvErcwRRcukXxiHMlJ6tqzZiP1jIk+Sumz/+dTjPf5S8tlYCE0sXHdKGLObXmNV6LUTMw6nXGtnIi99g3LF/xJgscV7N4sC+KRr15Y+ZJXpq6mEWtP2Hhkxr2friUX1xH8XFUBE6SpbrMkXDr3o8uDnP4NTaTZ0b4NYwoo4FiXfQqSVYnOnS/xXDxqgHJfwQ9v52Lv3Mhqa/05ODuP8ZXImkDx7dfAZ9BRK56DR9nCWPqevaP/5wbW7eSNbEDfpET6BGpI31eX375Ogf73lPoMb1jrW8OpUcAzwYH4QD08i7i51X72H6pmJfaOUBhMu8cyaNf37F83MZBPmc/b0rTV/F84nmutI2gWR2FkKIgicXHb9C+6/N89rAnKqBvgBclOWtZEJfMtGbt8AcwpHLuIgQ9EYy60pLs8WgSgOtNV+yww9U/kMBAZXldObv593/SiXx9Pa/2MyWtWrdEd/pp5u88QPbAp/FRSDh3nMDsF5J45V/RLE1x49e4xry4/HlaayzXdRvqYMKCBHHnL2LAZtT1ST0PSQ1oL1xELyQUD3WmkTOARPmeQVB8PJ58A4iM7zk45PvyReSlo9UKcKu/gZjC0Z3masGJwiKMOGDIusYRXQnZO1bgsMOspkYDRvd8rgrqzKh12RkcM7jwXDP3Py6GwoPeAa7MSUwn0dAOfyVQqkWrk3Bycqx1Bll/PpHk4gLyFj/FY4vNdhj0GBtnkC3ABwA1IaNnMuHYWN7fcoGwqNU806K28wRl5+SMi7NEUUEhtnRZ/VL/eSYJQCB0uioupsBokPdILUcQ+VofNOZ3rcIbj8rCzTqupEoBRrPZVCG5MXbQMKY0Kq9bUmgIqGM3U/UcrplutSOOdoKsmwUYcazG01UTTQkBCn8GzV7En5uXL0Gyc8XXzNkaMxM4fF6Ps7OSlD27SBoZxUOaCuVVp6siRi0FWoGmsZPNS9cz9WzUSpxCWmKnSKT02I9cvjaYlv4VZRQ4hIXhoDxMYdoJ8tQTadGtkXyzFOdQrPNAU0NkV9fYNfIjQplIbKaewFDf6ueVJSX2ShClpRRA5bLVyNh5+xKhTGTf5RvoG8vhN8Zcfrl0E7WPLw+VnbsyiOAgOJR8llJ8uM2+ylDbo0ZLYYERKN9wqpZtCFHtIPFsCX69Kkm2lVFylvVzPyQheCLLJ9uz4uUlLFgezoopkbiYW3E1um6j9DxnUiWCegbWJGnjDrHOqEtzSbuSS6nhCrk6gSHvKikXXLB39aeZt6bSXlvVbTQhrXZyMmkfh54axNnmrpRe0GF+Eyginqd9nx+J/SmZpPH9SQ1qgYPyJtq0bNzf+C99Rvne1YcWJKcwZnaMp9+hGAaUPMKEFt74KPSk5+TjGRzOE67mtbGntZczhoQEFiQ6M8C+mBR8iAr2MmvcamScw3gz/AhPxG5jnLIro7wEJ0/9xoIsN6JGhnKrD1Q0pnPX5qz6Zhe/5XWjdxXDEaV/MC0cc9m7bg3hxk54GLK5WBrMsF4tUHo9xpgRm3ltw5u8XvAsw7q0wENZzPXLmbh2H0YXPwVQRMLn8/kiszuzVg0lyBOmTj7EuHlLWN71M6Z1dbt1LarVVa5WgoLffya2MJg/d/axeep6RhkdHR1tqbDh3Fpe+dtc/h2zhzP5RrTn97P1263sLYlgRLfGlffAKh98+nRAlZtG4eVU8tNyMGo8cWrZnsb9B+If6ACSCx59+uLtpKU4OxNt2mW0N/TYNX0I725/okmrshvJSMHetaQmFmEXPozQHv61MPYS4k7G85M6hOmh3vLUi7jBtiNJXPMPJ6qpIwqUBAS04jFHLQfPnOTT+ATWJKVwOB/Cmreis5O5VokmPh4Up59jTfxx1l3IINuxKSOC3M28aXUySoICg3mEDDbGH+GjE+dJVDRhUv+BzAs0D7Ml3JqqSY75ir3aCAZE+lX+NJxdU0Kbakna/wMxMdvYFXuWAu9wej3cBLVkh2/H3jzskcPJvT/wbcxWftgdR1KmILBzb9p4Kig5tYYZ7ycROWMho0M1SEg4BLbF/cwmvtylpeOgSHxVlugyb/Jk1s5fzuk245k6LBgH2zx1vSLZ3tJqSBi4vGUqE5ZdJvLtZcx83O/+D2WNOfz2/iRm7vFj0or3GNrE5qfrG1sLNyiUNBs+k1lDHTmwaDILf864vzPJxiz2L53CnB9VPDlrBkNsBn1XsHnqhojxBsc2biDlkXEMD6ky3XUfUEzy5tUcDRnNM+3dbB7kLmEzahs2HjBsnacNGw8YNqO2YeMBw2bUDZHarnwigM+Af9VHpWzUG/8CYi0Xtxn1HaHnxroJbO3cgx3v/krJnWQnhB5dRgq5l/NqkMsh9uNXeX31r5y9mld59vsjQANcq3gssBbYcwf1BMg0lS+ZPiNrKXO/Ugh8D2TdB7oMwF6gH/CTZUVaYdSC/OTvWfbmOEYOfJw+fQfzzIS5rDuac39Pq9Qn4ibX9x+isCCX3L2x5BtqW5CB3H+OZFOfIez+7GQ17VnzyicAt556ucN3MKrECzgKJABVLZRhicz9SiLwNJByH+hSAuuAvsCzwIWai7T8MVHjFXZ+8m+OeQ3mxRmt8TamsW/tSlbNLMVn3Xz6ef4PPiYkeRD4+ny0LZKw7/M8XnfwJL2woGu0eOUTd2SDdq59fapFCbQBjEBVq0hZImPDMtTAauTO8S1gI1T3KKXlt6GiKU/931cMU6lMTzFFEuGWRtzkXziRqqefZ325hTrGkMKF2XNI+v0i2pyb6PVqNEERNH3uVcKHt8bO9FaZLmk7p9b/l/T40+Rfy0VXYkBydMep0wQeXfYsDtvLr8TC12loYt8nQF1B19z5nDlygYL0HHR6Feom7Wg2djoRT7fGTrp9RZeSTePZuMm0Yd+X7r9+SKAD1LjyiTmNAF+qfsdiD+AH3ABCgYXAILP9RmA58vj7DOAPvAK8SrU3U63QA+8BK4EMoAMwD9kz1YbtwIvAFajixfOq0QHBwCXTtnmE8Tdglel7Te1zBeiCHDJ/ZvotE4gEhgPvI5+3JbrKcAPmAi8A54CQqk/DKt8i3TJoAIE2OwutsgnN/O77hxX/QGSTE3eMG+kqHELa4q7OJPf0Ac7MOc7Nko30HhWIhKAkdiOntxyTjU1SorBXQ3EuWuGIRiGZVmJRYiy6RGbcOSpNWYlscg4eJiddiSaoNZ52meSdPcy5eZNRBn3Hw53sb63oUpJymMyUQqTG4fiHecq2Y9cOh7KmrWnlE3PaAjOo+uo2Qb5BNMhJmFHIYXKQaX808AkwH+iI3Am8BbgA42poX2uZhnwDz0f27F8CTwI7gF51rKsm7IDdwBHgOeT8Q3vTPnczuWiqb58mwBfIHWUkEIVs9F7AAmQjt1SXOYORo6//Uq1RI2pJ6eUfxNtPPS7GLD8uCmtbyL1Ad0gcfqydWN+uvzgSrxNClIq8Nc+Jrx9qIzb0WywydUIIYRD5a54VX7VpI76K2igKS4ymY/NFUW5RueKMF1eLH9u3EesjpoiLJTXoMuaIlEmdxfo27cR3S44Jwy1Bvbj+8RCxoU1bsWn2AbPfzSjdL+b17y0mxWQJY23P3SCEeFQIMcLst0tCCLUQ4nPTdroQwkUIsa7CsSOFEL1MZZiX16dCeZXprErmihDCSQixyOw3nRDiESHEACFqdaLbhBDeQoiK18Ia4oQQ9qa/FbGmfRYKIZyFEK8IIdyEEAlW6qpI2fUbV71YrbLfxedjmD35A853mM6iqPY41qaQ+wY7XPr3w1MFIiOJG9fLj20ljTPqsleOVM5o3Kt8k7lmJFfcgv2RMFKSY+U/MqiDlU8qxRfZw2SYthOQM7JjkT152WcLclhZl1nRk0Ap5T2yyrR9HCz+bwuHkeuoAoYB1wFH03aIFeVYgjXtMw3oBvwTmA60u0PdCuQwvIYJEitTO4LC0+uZMW0tN3rN5uPJPWjUgCLvqpCUKhQSIARWPzQrmS3PZMGxCrUKCRDGCp1H2ZeqKmDxyie1QMUfN6NAHouvRw7jy9WBe/LvH2qkLXIYK5Cnf2YBPyOHuGrqdhbAmva5DJxADqc3AZO4s6ShEchHzplUg1X3hvH6Lyx5+wtyekXz/pSGbtDCZIRGig/FkqsHyaM5rp7WmYvk5CIn1wzpFKbLc1qipMRqh6bU2CMh0F+7RqnJrkWRlluzZKaVT1KSz1Y+fq8r2iHfnMeAsAqfFhVkJZNsAVV3aNXJtDXt22P2m960HY7lxugAPGQqLxDZ6Mq2W1lYhjkaU10r84iWtk8RMBr5POKQvfg0bm+D6nRVpBg4xR9j7yqwot/VcWrjKvbRkzcG+ZKXeuFWPRSOPgT4OTesJ1kMVzjzypNkNFZSdDaVEmGH+9DhNLI2Y+rWAZ8QNdcSEzj+16Fc9DGiLehKt+2z8LM4TlbiGBaGWpFI8W+L+GHwRhw1xWgzwui0cykBjli88skdU5bJfQ85O/4EsnGdQU5gBZrJSsjJrVXIiR430+9DLZRpDIxHTh7ZA62R52QTkBNl92qWtDngCixGfvhDj2xQI7C8feYge+rDyEOcZchGPpDyMw3V6arILuAmMKD66lsxT32dU6cz0GWlsShqV7lddl3eJOa9QfW54GfdIzng6KehJDUVnWMQ/kMn0enl9tYvOqBsSej8mRTM/ZRLiZfI0/vj3jUQlQGrukxVt5fp/GI68TFHKbh8Dr2jJ46hPiiLBThKgIKgQSPo/J8lrF6bQOeJ4fWXy1gABACfIk/JKJA9UU/KGzXAG8gh5t+RPWYUMITyBlmdzHuAB/I0TxayJ9xK7TPf4cAH3NkwwQV5iu0tUz1dkDufp011rql94pDH0V8jGzSmY9cDrwO94dbFq0lXGUXIMxaDqDH6+N979VJ/mN8HjONMZmPCvtxOxw734yCxKhrgyic27hwj8A9gM/Iz4C2rF29QEbONBrbyiY07xwi8hDwsWUuNBg33Zy7TRnVInnSZ9BFLfDaQEuBu65UfdBTICb8dQA/LDvnfC79t2HjAsXX0Nmw8YNiM2oaNBwybUduw8YDx/1HlIZ+vIFDTAAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoiGQ0pptjNZ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "forty-turtle"
   },
   "source": [
    "It's already easier to to spot \"the problem\". Now let's look at the same code in PyCharm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olympic-lotus"
   },
   "source": [
    "![IDE.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAOEAAAA8CAYAAACQE92LAAAABHNCSVQICAgIfAhkiAAAABl0RVh0U29mdHdhcmUAZ25vbWUtc2NyZWVuc2hvdO8Dvz4AAA8xSURBVHic7Z17dFzFfcc/997Vrlar99uyHpb1siVZ2MKWbXDs2sFASNIQICGxgRTatKUl5IQ00NMDLRxKT/o47Tlt2p6e056SJtCkFEoDxPhVIAEZDDa2ZdmybD0sS1pppZVWj92VdvfO9I+VZMmW0MqWvAuez3+zc+9vfnPvfO/MnbnzW62qqkqiUCiihh5tBxSK6x0lQoUiyigRKhRRRolQoYgySoQKRZRRIlQooowSoUIRZZQIFYooo0SoUEQZJUKFIsooESoUUUaJUKGIMkqECkWUUSJcDLR40ss2UZoVK5dTw7FiPRXLk9QN/hSg7tHV4qhg6+/8Gd/6UjXJRrSduYhmL6TugT/lobs2kB5DfikuR4t0P2F5lZVHLCEeOy4IRWxdY8vaOL6Rp5GoAwGTv9sf4riY5zw9gYf+eANrD77Lox+YkZY2WSglX1zPy3cmYQFCF9r42p+3cVZEmr8A9Bzqvv0E690/5ievHGfkEht6xg1srRac+FUDA0uwa3Ne+/Er2PLgo6zp+hf+7RdnCCy+C4pFwLKUxvUEnR3LJK+/HeCgHyRgXkljXxCS1j1HqNsH1nWVHLx9ofmRE1d2GzdlHeeNH18uwJhgrJ36/znI6kfuYM07zRwZUvu3Y5E5RWg4dB5YZ2FTssbQgEn9ODCtoWlWnS/WWLglU8MmJC2dIZ4/LeiXYKRb+OFNBtla+NiSHTa+CchIe8IJ7CsK+fs78tmUCd0n23nq3y/QMDZRflIqv727nF2r47GbAU7Un+OZV/rpFiCFICBgri57vnwAPTmNb99Xxq5KB0nmGMfeb+WZl3o5P3WOTlZJCdb2/6V97JJzM9ex7cZCrBP133DbSgDEQAO//rCVMQlYMymurKYwIwGLHMfT1cip5h78EtCSWFG3hfyhwxxqcmNqCRTcuI0V/iO83+jCjMT+BMLVSMvQrRQVxnGkQfWFscgcItSoWx3H2vEQz+4zcdl0vrneQPNcPGJtpYUdIsRz+wRui87XN1l4sDDI35yXmAMhnngjhJ5o8OQWnQMHghwKhXtCGfHDWKM0O8gf/OW7fN+azuPfq+ZPtrvZvceHwMK2e6q412zh/j/qwWlL5bHvreHpz33I778zxtV3ShZ+454q7tXa+N3HnXTY0/n+o5U8s22Yhw76J+zr2Ox2xr0+Lh0wC/cx3tl/HD2jhi2Vgob3TjIowpUXMmw/q+JGCmUjh9/qZMySSfn6DVTlv82RC36kHOH8yWayNq6h2PlrOhPXUGLvouG4iyDAvPanIb34/Aa5diuoAWlMMvvEjAZ5idDcadIZgoBXcHhAMnV/NY3iFGjqEvQJEAFBfS+sSNeYnAMQkqkGIQBzIh35gEhy+kgvTT5J0DPAnsYAy3PsYfu6neoinY8Ou+gKghgd4rXj41SWJC7O+Fq3U1moc/SQkzM+gd/t5tXjAcqLHTPsa2jMWiMpEUIghAQk0hTh9OQTSHOQkqwz4OzGL0AG3HS7xkhOS0GbNOFt5dS5APmVG1hT5qDn1GncwQjtz4r2CXmKaDJnm9W1sHAmMQUzJGvoGrU1Vn44MTzTDRh3La5zIVNMNXFTSDTtYlMydIPtu+t4/Z6J8q0W/I2L985j6DPrL4RE12c2ZCklV9a4NTTNQnbldrZUTPxixGH2Tfdf4nW2M1C2nhzfaU4NBGcztADU+2CsMqcIhZzZvC5pf5hC8tGJAP/au0SezYMpQhz46WGePLE0MyKmAGNanXVdm+h5JhGM+f3YMhIwYIFDYImUQXob3+Jk31xnxpFeuoq0wVacCSspz+vkWJd/4VLSHDjsJmO+8YWeqbhGzD4cldDthZU5OikaaHE61enaRVFKSdswlOXqpOmgWTS2rY3j4SLt2iw8Cj+NHZK1a9PJtoBmc3D3b9XyV1sTZpQvx0J4kxOoSDOwxenYLPqMh8mc+cLPqQ5B7aZcyuwa8enpfLnGSnObd9pcjqC/rZVgcQ3F8bO7KU0T07ATbzPQdR1dmyhcehkelqTmZBOvA0YS+WtupqbAMXWNLRmrqcz1cu5UI02nnSRW3MByuxaZ/WnoOdWsTDlPR2fEC0uKa4yRnZ399GwZPUOSvCIL95UbbMiAwYBGgRDs7ZUIoHdQYs+z8NAaC19dqZPuFbzaIhi4ZAZ1W5FGS6vgwkK6Ci2OdVuWk9vWwZ6u8JAvtzKfO2wD/McxPyaC8+dGSdxQyjO7S/nDnVnkuLr5p31ueqaN2sSgD8+yfB6/v4xHv1zM730hg9DHTo6MzJcvON8yQnxNMU/eV87DW1MIHj/H07/04BHT7fehV9/NzQV9NDc5Gb+0mxr3IZKLqahaQ1lpBYX2Qc67vEgEXs8QltwqqqqqKV2RR7yvg3PtLsYEEJfN6toKaD1M80AQ4R/E7yhndZ6Jy+khOK/9CRJK2bb7Xpad+TlvHu+7bAJJERtEvFivmB0tuZrPP/Ag6xJaefun/8yH3bGwYKiRVH0vX79rM9azP+ell+rpVx1hzKJEuBhoCWStqiXVXc9ZV2yIMLF4A4XmGc50DKkeMMZRIrxOSTd0diU6eHHUy4ApptI/GhqJtmvXHeoD7uuQkjgLuxId7PH52ZXomJFWXHuW9NtRRWzyhQT7VA/44qh3Ro+ouPao4ahCEWXUcFShiDJKhApFlFEiVCiijBKhQhFllAgXg5gL9KSYD2tWCpnplpjY4KVazdUSo4GeFPNgtZP3uTLW1aVij7IK5vyA+zOBtpyq25/jltXx9JxrwrfAxRh92f3cfWsV7jMn8c52rp5D3YPfZe3ACzz//B7Oj1xykGaj4PbVlMR56Ok3L/u9wOynz7PQFSKNhOoyNt+az4qaHIoKoP+c9+JH3fPmxw7asnw270xktHlkRkiOa2HfHBmlt9VL3KpCVqb66XUGorbj0lJZWTnjh1OnTkXJlSVAuulueh305iUJxBSdQE8SX+M53j0NekEhm6oWmq+YIujnwof9ZN6WTfbpUZy+6LhhmS66SwUZNbQcqm5/irz+vYylryU9KQXZv5/69/bRH5SAQfb6Z9maeIx2o4xlSclYxk9zov4FWoaCgIX8m/+W7SvtAIieF2hra7+4uXzSvvsAgbQaUpOSEH37OFR/gP6gRM/7Fvfs2IJt4oXh1t07wnZ6f8ar+w9O9IpzB3qaQgrMEJih2RVqZGRRVZ1BmgPGul2cOdTPyGSXFe+gsC6PvFwrhggx3Ork7MfD4Se6lAgTLg8oM1nuPPkA8YkUbcwjb5kNiwgy3NZD81EP/gV97a2TtbWSAvdZPm4cj7gn0fLy2bw9nbiJ63vDrsyw265uPtjfH94S9kn11+PJv6WEZe52jh7xYmpWlm0vpWD0AkcPj2BGYn/yUg2NMOjLIjVTx9kRnS+GYvizNZ0kWw/1+5/Fqy2neucT1K1qYE9D98TN1rEmG3Tv/Qs+GreRWfs4t2z8HL37/49RGaLr0GO8+L5OQtl3+VLBHPatnby571V8RiE1O3/AhooG3jzZg3D+hJf/80X03F18ZWOI9177L1wCkOa0kBdzB3q6SAifa5Th4dmO0HAkmTTsPc0pSyKlO4ooKx+ZaMwGGbWF5Aknx172MG5xUPz5FZSXNnPi7GIMLA0yawvJo5eGVwbwxyWxcnsBFWU+jjUtfTAo6ezi/Z91oeUup65O0vR6N0MCmIpLNE/9xRhd7/eScWseBe0tOFPyWJE4RNO7I+FN1/Pan45JMKCRGKez0PgIi0UMi1Aw2N2IVwA4cfZ6qErJQad7otFLgv0n6RmXwBgDHccYzErCrsGoBClCmGiYcq4LKxjsPhV+Twx14XSNUJGciUYPUgpMUyCFAATCDM4aL3XOQE9TSDwn2vHMkTfSMchoQEJgFJczRFayFRgHzUpSuobn2BBjJmD6cHUFyc2yo58NXn1T0awkpmsMnZgsf4SerhA1GfHoBOa1r6VmU3tHbjigM0BhBVvXAeMDNLzcOWNj9+xVD/fUmoBwoCqJmH5OBPWXw26aG5JZW1dEit1KX/0FBgMR2p+1UvPkLyFT74Sx9y4okdMEJKVEmxG+YWa+6P8Fe/deuf2wmPQF3YsrD/Q0cf60x/KkrUlZa5pBRl05G2rD+ZphIJxXXNRlaNpkmRd90WYJjzGr3x4XR150caXD0cj8m6/+En+bG09NEVmjTs72XuWuySh+QW2JPfFNoqHrF+f8dV2f0Wiiz9UEepofKU36P2jmTNfS1FlKJkQXtq/pWkxd3/nrb5Bak0uKq5/e5EyKV3pobLmSobqFOKskFIjeDpKpFRKHwxH+QY+VpUOdtMKNZNh09PgKVuSlMTrUG2Fj19AMC4YRh6HpoBnoehyGscDF2dA4IUsaiXYbhmHBmBFybv5AT1eMDDAyIEkpSMKmAxYbyzaXsLrMNsN/GRSY8TYcCTq6oaEbWmT5MsDogCS5OBVHnIaekEjOcgte90IDJ0vEWIDxoLyyjiRkYlrisMVP+DfZ9CKov2VZLmVF47R/5KTlo2Ec65aTm6hFZn8aWkoS6Ql+htzRE6EFwgLMz8/H4/Eg5h08XysEniErVTv/muXJFrzdr3GoyRnZzdar2Xz3dyiZnN6knK/u+gaIDo698RwNQxF64P4VJ50Pc+Od/8BNOoy3/IiX609MTcQEz+7ng8HH2fmVG+n97yMMLVocCRP30Qs4NuZR+7VCDGni7eyj5fzMIZ/s7aPVWUjpb1az2gCEn/ZfnuP8xNrj3Pkm/Uc7cGzM44a7l2OIIMNtXZw5u9BJGYn7cDPuK6yldA/Q4Syi9M5qVukQamnn0KFhxHz1tyaxsi6FsRPn6PVKpLeHls4yKurSGXrLHf4rgU+0P4HVQdHGTIzW87iitDwBoNXV1cn8/HwuXLiAzxdFT6aj5VB1+5NkNf2At9vmmv+PDWIz0JNiPmwFeVTWpWFxdtP4wSC+KAbiscScAD9lyOGTHPjHpzi+qpZUFdHsU4Mc99H5jov+/lDUY5PrnZ2dsSdA2Uvjnu/EfC84hfTRd/rdGZHW0g2dR1KSSDd0lY7BdKJ7mHuDdtIWeP5SYKSmpj69JJavY0riLNzlSGCPz89djgTcQqj0ZyQ9uARzJirGzBLwSErSZaEEVfqzkV4KlAgViigTK4uCCsV1ixKhQhFllAgViiijRKhQRBklQoUiyigRKhRRRolQoYgySoQKRZT5f0MNhIf0KR86AAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "color-intake"
   },
   "source": [
    "Aside from Dark Mode *obviously* being superior :P we get a lot of information here. PyCharm's syntax highlighting is more precise, distinguishing between keywords like `def`, function names like `hello`, unused variables like `text`, function calls like `print`, strings like `hello + text)`. \n",
    "\n",
    "But it's now also obvious that there is *also* a problem in the first line: there's a `:` missing in the function definition.\n",
    "\n",
    "This is only the smallest bit of what a good IDE (integrated development environment) can do for you. They can also do things like:\n",
    "- Keep control of big projects, by for example finding where you defined a particular function or variable\n",
    "- Rename all uses of a variable everywhere in your project, if you're cleaning up some code\n",
    "- Detect when a variable isn't used\n",
    "- Detect when a variable isn't initialized before being read\n",
    "- Detect when you're breaking code style guidelines and suggest fixes\n",
    "- Notice that you forgot to import a package\n",
    "- Easily do all those Github actions for you\n",
    "- Tab completion of variable names\n",
    "\n",
    "The list goes on. Learning a real IDE can be a bit intimidating, but it pays off in many hours of your time saved both with convenience features and because of the problem-solving tools. We're not mandating you use a particular IDE in this course, but you're recommended to pick a good one. Particularly good ones for Python are PyCharm (by Jetbrains) and Visual Studio Code (by Microsoft). Both have free versions available, and if you register for a student version you generally get the full features. There is also plenty of information on the internet on how to use them. Typically just googling on \"product name\" + \"thing you want to do\" will get you in the right direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python environments\n",
    "When you start working on more than one project in Python, it can be useful to arrange for separate environments for them. This can be useful or necessary for several reasons:\n",
    "* Because some package in project A requires an older version of a package Q, while in project B you need a newer version of package Q.\n",
    "* Because you want to be able to copy your project to a different computer, and it should work the same way there as it does on your primary computer. (Like when we have to grade it...)\n",
    "\n",
    "If you just install every package user-wide or even system-wide on your computer, that can make it hard to determine what exactly you're using for *this particular project* and what someone would need to install to run your project. This is bad in science, because we want to be able to reproduce experiments. But it's also bad in industry, because you want to be sure that when you develop code in a development environment, that it'll work the same way in the production environment.\n",
    "\n",
    "Luckily, there are solutions. Less luckily, there are multiple solutions which can get confusing. Teaching each of these goes beyond the scope of this tutorial but you should be at least familiar with the names:\n",
    "* The Anaconda distribution of Python has the `conda` program to create environments with. These can be exported into a `environment.yml` file, and with this file someone else can re-recreate your environment. You would mostly use the `conda` program to install new packages into this environment. Anaconda comes with most scientific packages for Python already installed, which can make it a bit heavy but also very batteries-included.\n",
    "* Outside the Anaconda world, people mostly use `pip` to install packages. You can also first set up a *virtual environment* with either `virtualenv` or `venv` (the latter is newer but less widely adopted). Using `pip` you can \"freeze\" an environment and export it to a `requirements.txt` file. With the requirements file you can then initialize a new environment with the same packages.\n",
    "* You can also use Google Colab, which is a cloud-based version of Jupyter Notebook with some version control, commenting and collaboration tools added to it. Since it's in the cloud, you can also alter that environment without worrying that it affects your own computer. Like Anaconda, it has a lot of packages already installed, although you can use `pip` to install more as needed.\n",
    "\n",
    "When explaining what `conda` and `pip` do, it's roughly like this: `conda` installs just about anything, including non-Python software, into an Anaconda environment. Meanwhile `pip` installs only Python packages, into any kind of environment, including Anaconda.\n",
    "\n",
    "Although we aim for all assignments in this course to be *possible* on Colab, you should investigate which kind of virtual environment you want to use on your own computer and do some tutorials on it, because you'll be able to get better performance from running locally. \n",
    "\n",
    "### Good package importing practices\n",
    "It's quite common in tutorials that you see packages only imported at the moment they're about to be used. In a Jupyter notebook this can be many cells down. This is of course useful for focusing your attention on them. However, it also has a downside; you can't easily look at a file and see what packages you need to run it. And in the case of a notebook, if you're executing cells out of sequence because you're trying to debug something, you often find you need to hunt back and forth to import everything you need.\n",
    "\n",
    "It's therefore good practice to put one cell near the very top of your notebook with all the package imports you need. You can see an example at the top of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exclusive-retirement"
   },
   "source": [
    "## Where to find more information\n",
    "This lab only covers the beginnings of these packages. You can find a lot more information on the internet; these packages are widely used and well-documented. Good places to look are:\n",
    "* The official documentation. Just googling for something like `numpy.random`, or a specific function like \"numpy random uniform\" will turn up the relevant page.\n",
    "* There are many tutorials available for doing specific things with each of these packages. Again, just searching the internet will usually turn up something.\n",
    "* Stackoverflow is also a big help.\n",
    "\n",
    "As you get more experienced you'll probably start leaning more on the official documentation to look up a precise detail, than on tutorials. Although if you're starting a project that uses a technique you haven't used yet, it's good to just read up a bit on it. This software is quite friendly to self-study because there's so much good material on the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to submit your work\n",
    "This assignment isn't graded, but you can use this to test the submission workflow for the assignments later in the course.\n",
    "\n",
    "Take the file `Lab1.py` and put your solutions to the programming exercises in the various functions: replace all `NotImplementedError` instances with your code.\n",
    "\n",
    "#### Running locally\n",
    "You can run the tests file to see if it works correctly. From the command line:\n",
    "\n",
    "```pytest Lab1_tests.py```\n",
    "\n",
    "You can also run them directly from the notebook by adding a `!` in the cell to push the code in the cell to the command line: `!pytest Lab1_tests.py`.\n",
    "\n",
    "#### Running on Colab\n",
    "If you're doing this from Colab, you can upload the Lab1.py and Lab1_test.py files to Colab so that you can run pytest there. To make sure Colab uses the correct version of pytest, use this line:\n",
    "\n",
    "```!python3 -m pytest Lab1_tests.py```\n",
    "\n",
    "### Commit & Push\n",
    "Once you're satisfied that they all work correctly, make a *git commit* of your changes to `Lab1.py` and then *push* them back up to your repository. This will trigger a run of tests in the repository. You can see the result in the \"actions\" tab. If they all succeed then you're done. If not, then look at the errors, fix them, and commit and push again.\n",
    "\n",
    "#### How to commit and push\n",
    "To commit something to git you need to preform two steps: adding the files and then commiting them. You can see a commit as a set of one or more files which have changes in them compared to the orginal version which is hosted in the online git repo.\n",
    "It is easiest to just add all the changed files to the commit by the following command:\n",
    "\n",
    "> git add .\n",
    "\n",
    "This will add all the chagned files in the current git repostoryt to the commit, you can also add a spefic file by just replacing the . with a file name.\n",
    "\n",
    "After adding you need to make the commit with the following command:\n",
    "\n",
    "> git commit -m \"Describe what is changed in the commmit here\"\n",
    "\n",
    "Note that it is good practise to commit and or push often with clear messages, this way your code is backedup and you can easily revert to older version if you make some changes with unintenial effects.\n",
    "\n",
    "You can then push this commit to the online git enviroment. Note that only by pushing you can change the online git repository! Just by commiting you only are effecting your local git repostitory.\n",
    "To push:\n",
    "\n",
    "> git push\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "MLCourse_Lab1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
